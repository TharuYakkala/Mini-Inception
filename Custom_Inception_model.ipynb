{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Inception Model from scratch\n",
    "\n",
    "Author: Tharindu Yakkala\n",
    "\n",
    "References:\n",
    "Going Deeper with Convolutions\n",
    "https://arxiv.org/abs/1409.4842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Building Blocks of the Inception Layer\n",
    "\"\"\"\n",
    "\n",
    "### 1x1 Convolution block -> 3x3 Conv\n",
    "class Conv1x1_3x3(nn.Module):\n",
    "    def __init__(self, input_channels:int , mid_channels: int, output_channels:int) -> torch.Tensor:\n",
    "        \"\"\"Instantiate a Convblock that takes image through a 1x1 Conv\n",
    "        and reduced channels to mid_channels, then through a 3x3 Conv2d\n",
    "        block which outputs 'output_channels'\n",
    "\n",
    "        Args:\n",
    "            input_channels (_type_): Image imput channels.\n",
    "            mid_channels (_type_): mid channels for the 1x1 conv.\n",
    "            output_channels (_type_): out channels for the 3x3 conv.\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch_size, output_channels, x, y)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv_block3x = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channels, out_channels=mid_channels, kernel_size=1),\n",
    "            nn.Conv2d(in_channels=mid_channels, out_channels=output_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv_block3x(x)\n",
    "    \n",
    "\n",
    "### 1x1 Convolution block -> 5x5 Conv\n",
    "class Conv1x1_5x5(nn.Module):\n",
    "    def __init__(self, input_channels: int, mid_channels: int, output_channels: int) -> torch.Tensor:\n",
    "        \"\"\"Instiantiate a convblock, it takes an input image of input_channels\n",
    "        into a 1x1 conv and reduces channels to 'mid_channels' then into a\n",
    "        5x5 conv that outputs 'output_channels'\n",
    "\n",
    "        Args:\n",
    "            input_channels (int): Image input channels.\n",
    "            mid_channels (int): 1x1 conv output channels.\n",
    "            output_channels (int): 5x5 conv output channels.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Conv block output of shape (batch_size, output_channels, x, y).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv_block5x = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channels, out_channels=mid_channels, kernel_size=1),\n",
    "            nn.Conv2d(in_channels=mid_channels, out_channels=output_channels, kernel_size=5, padding=2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv_block5x(x)\n",
    "\n",
    "class Pool3x3_Conv1x1(nn.Module):\n",
    "    def __init__(self, input_channels: int, output_channels:int) -> torch.Tensor:\n",
    "        \"\"\"Instantiate a convblock that takes takes image through a MaxPool 3x3 and \n",
    "        maintains same image shape, then into a 1x1 conv block that outputs 'output_channels'\n",
    "\n",
    "        Args:\n",
    "            input_channels (int): Image input channels.\n",
    "            output_channels (int): Image output channels.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of shape (batch_size, output_channels, x, y)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.pool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels=input_channels, out_channels=output_channels, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.pool_conv(x)\n",
    "        \n",
    "class Inception_block(nn.Module):\n",
    "    def __init__(self, input_channels: int, x1_out: int, x3_mid: int, x3_out: int, x5_mid: int, x5_out: int, pool_out: int) -> torch.Tensor:\n",
    "        \"\"\"Instantiate an inception block that contains 4 neural networks in one.\n",
    "        Args:\n",
    "            input_channels (int): Input channels of image.\n",
    "            x1_out (int): Output channels of the 1x1 conv (block1).\n",
    "            x3_mid (int): Mid channels of the 1x1conv_3x3conv (block2).\n",
    "            x3_out (int): Output channels of the 1x1conv_3x3conv (block2).\n",
    "            x5_mid (int): Mid channels of the 1x1Conv_5x5Conv (block3).\n",
    "            x5_out (int): Output channels of the 1x1Conv_5x5Conv (block3).\n",
    "            pool_out (int): Output channels of the 3x3Pool_1x1Conv (block4).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of shape (batch_size, x1_out + x3_out + x5_out + pool_out, x, y)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Conv2d(in_channels=input_channels, out_channels=x1_out, kernel_size=1, stride=1, padding=0)\n",
    "        self.block2 = Conv1x1_3x3(input_channels=input_channels, mid_channels=x3_mid, output_channels=x3_out)\n",
    "        self.block3 = Conv1x1_5x5(input_channels=input_channels, mid_channels=x5_mid, output_channels=x5_out)\n",
    "        self.block4 = Pool3x3_Conv1x1(input_channels=input_channels, output_channels=pool_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        block1_out = self.block1(x)\n",
    "        block2_out = self.block2(x)\n",
    "        block3_out = self.block3(x)\n",
    "        block4_out = self.block4(x)\n",
    "        \n",
    "        # contatination on channel dim, bring the inner neural nets and combine them.\n",
    "        return torch.concat([block1_out, block2_out, block3_out, block4_out], dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The mini-inception model\n",
    "\"\"\"\n",
    "\n",
    "class inception_mini(nn.Module):\n",
    "    def __init__(self) -> torch.Tensor:\n",
    "        \"\"\"Instantiate a custom inception model for binary classification.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of shape (batch_size, 1), output logits.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # first conv layer\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=192,  kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        \n",
    "        # first inception layer, consisting of 4 layers in one.\n",
    "        self.inception1 = Inception_block(input_channels=192,\n",
    "                                          x1_out=64,\n",
    "                                          x3_mid=96,\n",
    "                                          x3_out=128,\n",
    "                                          x5_mid=16,\n",
    "                                          x5_out=32,\n",
    "                                          pool_out=32)\n",
    "        \n",
    "        # second inception layer, also 4 layers in one.\n",
    "        self.inception2 = Inception_block(input_channels=256,\n",
    "            x1_out=64,\n",
    "            x3_mid=96,\n",
    "            x3_out=128,\n",
    "            x5_mid=16,\n",
    "            x5_out=32,\n",
    "            pool_out=32\n",
    "        ) \n",
    "        \n",
    "        # adding bottleneck layer to further optimize speed\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=64, kernel_size=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        \n",
    "        self.adaptive = nn.Sequential(\n",
    "              nn.AdaptiveAvgPool2d((1,1)),\n",
    "              nn.Flatten(start_dim=1)\n",
    "        )\n",
    "             \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(in_features=64, out_features=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.inception1(x1)\n",
    "        x1 = self.inception2(x1)\n",
    "        x1 = self.bottleneck(x1)\n",
    "        x1 = self.adaptive(x1)\n",
    "        return self.out(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inception_mini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    !pip install torchinfo\n",
    "    from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "inception_mini                           [32, 1]                   --\n",
       "├─Sequential: 1-1                        [32, 192, 111, 111]       --\n",
       "│    └─Conv2d: 2-1                       [32, 192, 222, 222]       5,376\n",
       "│    └─BatchNorm2d: 2-2                  [32, 192, 222, 222]       384\n",
       "│    └─ReLU: 2-3                         [32, 192, 222, 222]       --\n",
       "│    └─MaxPool2d: 2-4                    [32, 192, 111, 111]       --\n",
       "├─Inception_block: 1-2                   [32, 256, 111, 111]       --\n",
       "│    └─Conv2d: 2-5                       [32, 64, 111, 111]        12,352\n",
       "│    └─Conv1x1_3x3: 2-6                  [32, 128, 111, 111]       --\n",
       "│    │    └─Sequential: 3-1              [32, 128, 111, 111]       129,248\n",
       "│    └─Conv1x1_5x5: 2-7                  [32, 32, 111, 111]        --\n",
       "│    │    └─Sequential: 3-2              [32, 32, 111, 111]        15,920\n",
       "│    └─Pool3x3_Conv1x1: 2-8              [32, 32, 111, 111]        --\n",
       "│    │    └─Sequential: 3-3              [32, 32, 111, 111]        6,176\n",
       "├─Inception_block: 1-3                   [32, 256, 111, 111]       --\n",
       "│    └─Conv2d: 2-9                       [32, 64, 111, 111]        16,448\n",
       "│    └─Conv1x1_3x3: 2-10                 [32, 128, 111, 111]       --\n",
       "│    │    └─Sequential: 3-4              [32, 128, 111, 111]       135,392\n",
       "│    └─Conv1x1_5x5: 2-11                 [32, 32, 111, 111]        --\n",
       "│    │    └─Sequential: 3-5              [32, 32, 111, 111]        16,944\n",
       "│    └─Pool3x3_Conv1x1: 2-12             [32, 32, 111, 111]        --\n",
       "│    │    └─Sequential: 3-6              [32, 32, 111, 111]        8,224\n",
       "├─Sequential: 1-4                        [32, 64, 55, 55]          --\n",
       "│    └─Conv2d: 2-13                      [32, 64, 111, 111]        16,448\n",
       "│    └─BatchNorm2d: 2-14                 [32, 64, 111, 111]        128\n",
       "│    └─ReLU: 2-15                        [32, 64, 111, 111]        --\n",
       "│    └─MaxPool2d: 2-16                   [32, 64, 55, 55]          --\n",
       "├─Sequential: 1-5                        [32, 64]                  --\n",
       "│    └─AdaptiveAvgPool2d: 2-17           [32, 64, 1, 1]            --\n",
       "│    └─Flatten: 2-18                     [32, 64]                  --\n",
       "├─Sequential: 1-6                        [32, 1]                   --\n",
       "│    └─Linear: 2-19                      [32, 1]                   65\n",
       "==========================================================================================\n",
       "Total params: 363,105\n",
       "Trainable params: 363,105\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 149.29\n",
       "==========================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 7570.02\n",
       "Params size (MB): 1.45\n",
       "Estimated Total Size (MB): 7590.74\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(32, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train = MNIST(root=\"./data_mnist\", train=True, download=True, transform=transform)\n",
    "test = MNIST(root=\"./data_mnist\", train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.8196, 0.6902, 0.6824, 0.9176, 1.0000, 0.9961, 0.9961, 0.9961,\n",
       "          0.9961, 0.7686, 0.6824, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.7882, 0.9961, 0.9294, 0.8980, 0.8980, 0.8980, 0.9529, 0.9961,\n",
       "          0.9961, 0.9961, 0.9961, 0.7373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.2275, 0.5765, 0.0667, 0.0000, 0.0000, 0.0000, 0.1294, 0.2196,\n",
       "          0.2196, 0.5255, 0.9961, 0.9020, 0.0667, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.5569, 0.9961, 0.9961, 0.1412, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0078, 0.7804, 0.9961, 0.8431, 0.0196, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.4196, 0.9961, 0.9961, 0.3373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1098,\n",
       "          0.8745, 0.9961, 0.6980, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0392, 0.7412,\n",
       "          0.9961, 0.7961, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0588, 0.7176, 0.9961,\n",
       "          0.9451, 0.1647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0627, 0.1608, 0.3137, 0.7490, 0.9961, 0.9961,\n",
       "          0.4980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0118, 0.8039, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961,\n",
       "          0.9882, 0.5882, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.6471, 0.9961, 0.9529, 0.6745, 0.6039, 0.8196,\n",
       "          0.9961, 0.9961, 0.7294, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0235, 0.0627, 0.0510, 0.0000, 0.0000, 0.0196,\n",
       "          0.2863, 0.9098, 0.9961, 0.4824, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.7020, 0.9961, 0.8196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.4235, 0.9961, 0.8196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1255, 0.3686,\n",
       "          0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216,\n",
       "          0.6510, 0.9294, 0.9961, 0.5373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8471, 0.9961,\n",
       "          0.7922, 0.0706, 0.0000, 0.0000, 0.0000, 0.1608, 0.6706, 0.9843,\n",
       "          0.9961, 0.9961, 0.8196, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.8314, 0.9961,\n",
       "          0.9961, 0.5922, 0.1412, 0.2039, 0.5882, 0.9294, 0.9961, 0.9294,\n",
       "          0.5608, 0.3333, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1098, 0.7490,\n",
       "          0.9961, 0.9961, 0.9608, 0.9725, 0.9961, 0.9373, 0.5412, 0.0863,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118,\n",
       "          0.3294, 0.7843, 0.9961, 0.9961, 0.5922, 0.0863, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test one batch\n",
    "get_batch = next(iter(train_dataloader))\n",
    "get_batch[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
